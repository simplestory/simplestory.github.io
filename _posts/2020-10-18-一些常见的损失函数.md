---
layout:     post
title:      "一些常见的损失函数"
subtitle:   "some loss function"
date:       2020-10-18
author:     "Simplestory"
header-style: text
catalog: False
mathjax: true
tags:
    - Deep Learning
---

> 学习了那么多的深度学习算法，损失函数总是绕不过去的点，但好在一般情况下使用的损失函数都比较固定，偶尔会有一些随缘性的改变。这里主要列举了一些常用的损失函数。


### L1-loss

L1损失函数，又称平均绝对误差(Mean Absolute Error, MAE)。数学表达式如下：

$$
MAE = \frac{1}{n}\sum^n_{i=1}\vert f(x_i)-y_i\vert
$$

其中$n$表示训练批次样本数量，$f(x_i)$表示模型在样本$x_i$处的预测值，$y_i$为样本$x_i$对应的真实值。


### L2-loss

L2损失函数，又称均方误差(Mean Square Error, MSE)。数学表达式如下：

$$
MSE = \frac{1}{n}\sum^n_{i=1}(f(x_i)-y_i)^2
$$

其中$n$表示训练批次样本数量，$f(x_i)$表示模型在样本$x_i$处的预测值，$y_i$为样本$x_i$对应的真实值。


### Smooth L1 loss

L1损失函数对数据离群点并不敏感，而L2损失则过于敏感。为了让训练变得平稳，才提出了该损失函数。具体如下：

$$
loss(x_i) = 
\begin{cases}
    0.5 * (f(x_i)-y_i)^2, \ &\vert f(x_i)-y_i\vert <1 \\
    \vert f(x_i)-y_i\vert - 0.5, \ &\text{otherwise}
\end{cases}
$$

这里只展示了对于样本$x_i$的损失计算，$f(x_i)$表示模型在样本$x_i$处的预测值，$y_i$为样本$x_i$对应的真实值。


### Cross Entropy loss

交叉熵损失函数(CE)主要用于分类算法中。

对于0-1分类，有

$$
loss(x_i) = -y_i * log(p_i)-(1-y_i) * log(1-p_i)
$$

其中$p_i$表示模型将样本$x_i$预测为正类的概率，$y_i$为样本$x_i$对应的真实类别，正样本为1负样本为0。

对于多分类，有

$$
loss(x) = -\sum^c_{j=1}y_i * log(p_i) \\
y_i = 
\begin{cases}
    1, \ &\text{the label of x is i} \\
    0, \ &\text{otherwise}
\end{cases}
$$

其中$p_i$为模型将样本预测为类别$i$的概率，一般模型会通过softmax后在计算交叉熵损失。

### Focal loss

这个损失函数是为了解决正负样本不均衡的情况，主要是针对单阶目标检测算法中锚框的正负样本比例失调的情况。

令

$$
p_t = 
\begin{cases}
    p, \ & y=1 \\
    1-p, \ & y=0
\end{cases}
$$

则可将交叉熵损失函数统一为：

$$
loss = -log(p_t)
$$

为了调节正负样本的比例，一个自然的想法就是用一个系数进行加权，如下：

$$
loss = -\alpha_t * log(p_t) \\
\alpha_t = 
\begin{cases}
    \alpha, \ & y=1 \\
    1-\alpha, \ & y=0
\end{cases}
$$

但这样处理并不能区分出简单样本和困难样本，正常情况下，简单样本的数量要比困难样本数量多得多。最后换用自适应系数后如下：

$$
loss = -(1-p_t)^\gamma * log(p_t)
$$

作者在实验中发现对自适应系数作调整，模型效果会有轻微提升，所以最后损失函数如下：

$$
loss = -\alpha(1-p_t)^\gamma * log(p_t)
$$

其中$\alpha$和$\gamma$都为超参数。作者在自己的模型熵实验显示$\alpha=0.25$，$\gamma=2$时效果最好。该函数仅在计算分类损失时用到，具体可参考Retina模型的损失函数。

### 致谢

>[Focal Loss for Dense Object Detection](https://arxiv.org/pdf/1708.02002.pdf)

>[何恺明大神的「Focal Loss」，如何更好地理解？](https://zhuanlan.zhihu.com/p/32423092)

>[【目标检测】RetinaNet: Focal Loss for Object Detection](https://zhuanlan.zhihu.com/p/65584372)